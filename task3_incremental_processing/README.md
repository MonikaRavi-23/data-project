# ğŸ” Incremental Data Processing Challenge 

> âš¡ Real-time model updates and data synchronization using **Change Data Capture (CDC)**, **Apache Kafka**, **Flink**, and **Python**.

---

## ğŸ§  Overview

This project demonstrates **Incremental Data Processing** using **CDC (Change Data Capture)** techniques â€” enabling systems to **react instantly to new or changed data**.  

When source data updates (in a database or stream), these changes are captured and processed incrementally using **Apache Kafka Connect**, then applied to update **data processing models or machine learning pipelines** (e.g., regression, clustering, or aggregations).

---

## ğŸ§© Task 3: Incremental Data Processing (CDC)

### ğŸ¯ Objectives
- ğŸ§© Implement **Change Data Capture (CDC)** using **Kafka Connect**
- ğŸ—ƒï¸ Capture and stream **database changes** in near real-time
- ğŸ“ˆ Process data incrementally and update **aggregations or ML models**
- ğŸ”„ Maintain **consistency** between batch and streaming layers

ğŸ§° **Tools Used:**  
**Apache Kafka** Â· **Apache Flink** Â· **Python** Â· **Kafka Connect** Â· **CDC Techniques**

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

cd data-project
***2ï¸âƒ£ Create & Activate Virtual Environment****
python3 -m venv streaming_env
source streaming_env/bin/activate   # Mac/Linux
streaming_env\Scripts\activate      # Windows

**3ï¸âƒ£ Install Dependencies**
pip install -r ../requirements.txt

**4ï¸âƒ£ Start Kafka & Zookeeper**

Make sure Kafka and Zookeeper are running before you start the CDC components.
bin/zookeeper-server-start.sh config/zookeeper.properties
bin/kafka-server-start.sh config/server.properties

ğŸš€ Run the CDC System

**â–¶ï¸ Start CDC Producer**

Simulate or stream data change events (insert/update/delete) to a Kafka topic:
python3 cdc_producer.py

**â–¶ï¸ Start CDC Consumer**
Consume the change stream and update downstream models or aggregations:
python3 cdc_consumer.py

**ğŸ’¡ How It Works**

ğŸ—„ï¸ Source Database â†’ generates changes (insert/update/delete)
ğŸ”— Kafka Connect CDC Source (e.g., Debezium) captures these changes
ğŸš€ Kafka Topic receives and streams events in real time
âš™ï¸ Flink / Spark Streaming consumes events and applies updates
ğŸ§  Python Model or Aggregation updates incrementally without full retraining
**ouput:**
![terminal ouptut](https://github.com/user-attachments/assets/7cd72598-d8c9-4548-8b0a-8efbaf5fc53a)
![terminal output](https://github.com/user-attachments/assets/94a5d6f5-5b87-49be-9467-9d9ccc1237f9)

